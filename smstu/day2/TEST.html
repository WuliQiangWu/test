<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="viewport"
          content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta charset="UTF-8">
    <title>Title</title>
    <Style>
    	#webcam{
    		width: 300px;
    		height: 100px;
    	}
    </Style>
</head>
<body>
    <button id="run">开启网络麦克风</button><Br/>
    <audio id="webcam" controls="controls" loop="loop" src="" preload="auto"></audio>
    <script>
        //检查浏览器是否支持getUserMedia方法。
        navigator.getUserMedia || (navigator.getUserMedia = navigator.mozGetUserMedia || navigator.webkitGetUserMedia || navigator.msGetUserMedia);

        if (navigator.getUserMedia) {
			console.log('your browser support getUserMedia');
			
        }
        else {
            console.log('your browser not support getUserMedia');
        }

        var btn = document.getElementById('run');
        btn.onclick = startWebcam;

        function startWebcam(e) {
            navigator.getUserMedia({
                audio: true
            }, onSuccess, onError);

	        function onSuccess(stream) {
	
	            //创建一个音频环境对像
	            audioContext = window.AudioContext || window.webkitAudioContext;
	            context = new audioContext();
	
	            //将声音输入这个对像
	            audioInput = context.createMediaStreamSources(stream);
	
	            //设置音量节点
	            volume = context.createGain();
	            audioInput.connect(volume);
	
	            //创建缓存，用来缓存声音
	            var bufferSize = 2048;
	
	            // 创建声音的缓存节点，createJavaScriptNode方法的
	            // 第二个和第三个参数指的是输入和输出都是双声道。
	            recorder = context.createJavaScriptNode(bufferSize, 2, 2);
	
	            // 录音过程的回调函数，基本上是将左右两声道的声音
	            // 分别放入缓存。
	            recorder.onaudioprocess = function(e){
	                console.log('recording');
	                var left = e.inputBuffer.getChannelData(0);
	                var right = e.inputBuffer.getChannelData(1);
	                // we clone the samples
	                leftchannel.push(new Float32Array(left));
	                rightchannel.push(new Float32Array(right));
	                recordingLength += bufferSize;
	            }
	
	            // 将音量节点连上缓存节点，换言之，音量节点是输入
	            // 和输出的中间环节。
	            volume.connect(recorder);
	
	            // 将缓存节点连上输出的目的地，可以是扩音器，也可以
	            // 是音频文件。
	            recorder.connect(context.destination);
	
	        }
	        function onError(){
	        	console.log('can not get video')
	        }
    	}
    </script>
</body>
</html>

